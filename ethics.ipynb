{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics: A/B Testing\n",
    "\n",
    "1. Do you believe Facebook should have provided users with an option to opt-out of its news feed study? Why or why not?\n",
    "    * I believe Facebook should have provided users with an option to opt-out of its news feed study because that kind of emotional \n",
    "    manipulation is unnecessary for the sake of \"product improvement\". While I understand that their goal with A/B testing is to \n",
    "    determine the best features and nuances of their product that will keep users coming back and staying longer, it feels as though \n",
    "    this level of experimentation is too driven by data and completely overlooks the reality of the situation. Yes, users blindly agree\n",
    "    to the terms and conditions when they first create an account, but the key word here is *blindly*. Facebook, among other companies, \n",
    "    should ask for a second level of consent in regards to how much data users are willing to let the company use and to what extent. \n",
    "1. In the Facebook case study, the author argues the line requiring consent was crossed because \"this experiment tried to directly sway emotions.\" Now, think of a different \"news feed\" you regularly use (besides Facebook). This could be another social media site, or it could something else, like a news source like Google News or Gonzaga's Morning Mail. Describe a general \"line\" that you would consider crossed if this \"news feed\" starting running experiments on you that you would want to be able to opt-out of.\n",
    "    * I receive emails every morning from the New York Times based on a set of interests that I selected when I first made my account.\n",
    "    If the NYT ever deviates from those topics because of my search history, I believe a line will have been surpassed by far too much. \n",
    "    In this instance, the New York Times is no longer providing the product that I am *asking* it to, but rather the product that it \n",
    "    *predicts* I want to see. For instance, my sister's wedding is in a couple of months so I do a lot of online window shopping for dresses,\n",
    "    but this does not mean that I want to hear about the latest fashion styles or who was wearing whom on the red carpet last night. If I\n",
    "    wanted to know those things I would watch Entertainment Tonight. \n",
    "1. The statement 1) \"consent is worth adding a little complexity to the product\" reminded me of the saying 2) \"increased security comes at the expense of usability.\" The latter adage (#2) is referring to the effects of digital security enhancements (like changing our passwords frequently or multi-factor authentication) on users. In both cases (#1 and #2), there is a compromise between the user and organization providing the software service. The organization wants to be successful, which I'll note is defined differently at different companies. As users, we want to use certain software, but sometimes we also \"need\" to use certain software, even if we don't want to. Can you think of a software example for each adage (#1 and #2) where you \"need\" to use the software, regardless of its complexity, usability, or invasiveness? Does this affect your likelihood to opt-out of a study if you were given the \"option\"?\n",
    "    * An example of a product where I believe consent is worth adding a little complexity is in social media platforms. When I downloaded my Snapchat\n",
    "    data, I was surprised to see that at the top of the folder holding thousands of KB of location data were the latitude and longitude coordinates\n",
    "    of my \"home\" and \"work\". When I plugged these into google maps, my \"home\" was three houses off and my \"work\" was dead center in the middle of \n",
    "    Gonzaga. I turned on location services so that I could access the location-based filters. If there was a way for me to decide what my location\n",
    "    can be used for, I would enjoy Snapchat much more and feel like my privacy is more respected. As for the second example, where I *need* to use \n",
    "    a product, the Gonzaga multi-factor authentication is both frustrating and reassuring. When it comes to all of the data that I have stored away \n",
    "    in my onedrive, it is nice to know that there is an extra layer of security preventing my account from easily being hacked. For this reason, I \n",
    "    would be much more likely to consent to a study if given the option because I would be in the mindset of \"I have to use it anyway\". With a little\n",
    "    bit of luck, they might just make the product better by having access to my data. \n",
    "1. What else struck you about this article? Any thoughts on Facebook's recent name change to Meta? For example, what does \"meta\" mean and why do you think they are changing their name to it?\n",
    "    * The phrase \"Just because everyone else isn't doing it, doesn't mean big tech companies can't be pioneers of better ethics\" really stood out to \n",
    "    me. I 100% agree with the author that big tech companies like Facebook (Meta) can are remarkable pioneers in other aspects of the world wide web, \n",
    "    so I see no reason why data ethics shouldn't be included in that list. Now, as for Facebook's move to Meta and the metaverse in general, it makes\n",
    "    me want to use the product even less than I already do. Some definitions for \"meta\" that seem to match Zuckerberg's switch include: 1)\"denoting a\n",
    "    change of position or condition\", because Meta is going to extend into the VR space, as well as 2)\"denoting something of a higher or second order\n",
    "    kind\", which is also fitting because Facebook is the first major social media platform to make the jump into the virtual reality space of social networking/social media. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
